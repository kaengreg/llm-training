{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zGiKaSVrkr90",
    "outputId": "dcd1ea5a-6b3c-4221-efc6-815669ccd74a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 27 18:33:01 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   58C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJ3hpGEKHEpG",
    "outputId": "975371d2-1875-4d46-afdf-b1ea93eab28b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.0+cu121)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.24.7)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
      "Requirement already satisfied: transformers==4.45.2 in /usr/local/lib/python3.10/dist-packages (4.45.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (0.24.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.2) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.2) (2024.8.30)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.44.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.0+cu121)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.16.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.5)\n",
      "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.10/dist-packages (0.9.1)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.0+cu121)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.45.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.5)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.34.2)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.24.7)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.20.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n",
      "Collecting flash_attn\n",
      "  Using cached flash_attn-2.6.3.tar.gz (2.6 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash_attn) (2.5.0+cu121)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash_attn) (0.8.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->flash_attn) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash_attn) (3.0.2)\n",
      "Building wheels for collected packages: flash_attn\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Building wheel for flash_attn (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Failed building wheel for flash_attn\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for flash_attn\n",
      "Failed to build flash_attn\n",
      "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (flash_attn)\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install accelerate\n",
    "!pip install transformers==4.45.2\n",
    "!pip install bitsandbytes\n",
    "!pip install datasets\n",
    "!pip install rouge-score\n",
    "!pip install pymorphy2\n",
    "!pip install peft\n",
    "!pip install flash_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hCC1-7cjWy4O",
    "outputId": "71214b62-9a57-4cb5-c8e6-9e5ac7b979eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'llmtf_open' already exists and is not an empty directory.\n",
      "/content/llmtf_open\n",
      "--2024-10-27 18:47:22--  https://raw.githubusercontent.com/dialogue-evaluation/RuOpinionNE-2024/master/train.jsonl\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1291979 (1.2M) [text/plain]\n",
      "Saving to: ‘train.jsonl.1’\n",
      "\n",
      "train.jsonl.1       100%[===================>]   1.23M  --.-KB/s    in 0.009s  \n",
      "\n",
      "2024-10-27 18:47:22 (142 MB/s) - ‘train.jsonl.1’ saved [1291979/1291979]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/RefalMachine/llmtf_open\n",
    "%cd llmtf_open\n",
    "!wget https://raw.githubusercontent.com/dialogue-evaluation/RuOpinionNE-2024/master/train.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sQJOjWMiXnf9",
    "outputId": "f144af9e-23ff-465d-e0f5-27bdbe9ecad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversation_configs  examples\t requirements.txt\t\t      todo.txt\n",
      "Dockerfile\t      llmtf\t run_evaluate_multinode_multigpu.py   train.jsonl\n",
      "eval_grammar.py       qa_qwen\t run_evaluate_multinode_multigpu.sh   train.jsonl.1\n",
      "evaluate_model.py     README.md  run_evaluate_singlenode_multigpu.sh\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "OJhyRI3Mqm89"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imvladikon/QAmeleon\")\n",
    "\n",
    "def transform_sample(sample):\n",
    "    if sample['language'] != 'ru':\n",
    "        return None\n",
    "\n",
    "    user_prompts = [\n",
    "        \"Опираясь на данный текст ответьте на вопрос: {question} '''Текст''': {passage}\\n\",\n",
    "        \"Прочитайте данный текст и ответьте на вопрос: {question} '''Текст''': {passage}\\n\"\n",
    "    ]\n",
    "    user_prompt = random.choice(user_prompts)\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "            {\"role\": \"bot\", \"content\": \"Ответ:\"}\n",
    "        ],\n",
    "        \"inputs\": {\n",
    "            \"question\": sample['question'],\n",
    "            \"passage\": sample['passage']\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"label\": \"passage\",\n",
    "            \"length\": len(sample['answer'].split()),\n",
    "            \"segment\": sample['answer']\n",
    "        }\n",
    "    }\n",
    "\n",
    "transformed_data = [transform_sample(sample) for sample in dataset['train'] if transform_sample(sample) is not None]\n",
    "\n",
    "test_size = int(0.83 * len(transformed_data))\n",
    "random.seed(42)\n",
    "random.shuffle(transformed_data)\n",
    "test_data = transformed_data[:test_size]\n",
    "prompt_data = transformed_data[test_size:]\n",
    "\n",
    "def create_dataset(data):\n",
    "    return Dataset.from_dict({\n",
    "        \"messages\": [item[\"messages\"] for item in data],\n",
    "        \"inputs\": [item[\"inputs\"] for item in data],\n",
    "        \"outputs\": [item[\"outputs\"] for item in data]\n",
    "    })\n",
    "\n",
    "test_dataset = create_dataset(test_data)\n",
    "prompt_dataset = create_dataset(prompt_data)\n",
    "\n",
    "qa_dataset = DatasetDict({\n",
    "    \"test\": test_dataset,\n",
    "    \"prompt\": prompt_dataset\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211,
     "referenced_widgets": [
      "5dc02fd1f41045e1ac09d36615fc301d",
      "afc9b8bfe57243d5a42f8ae94128d00b",
      "e7e03f8a6708477ea39683f259d84740",
      "1e243f7f07784fa7aeb9f75c3e1650d7",
      "3cbafd95e6b24d53badafb03ce763974",
      "58ab37625ebd4ee189213b4b7a88da6e",
      "05ae84db055f43c9a457570db54ca18f",
      "1c9d77a3d12340c6bdcfacb381518f0a",
      "73221ce8efcf49ea8ce8a674e1261cac",
      "bd192e2ef9784258b1113b91e40c704d",
      "c9d09d65e3734b92b763c3740ffa3614",
      "3fa692168a794b2c9633426b2629ac8e",
      "abc3f57b4412431c812a664e0fba3419",
      "8c833bb16ef9460aa9593b9507e643a6",
      "e48ec8f3f32c4ce289bf68f1a9e49a57",
      "d8bfba7491e94ad1a3481da29bf4a7d3",
      "2d64e7767f574efd887b72c24f052023",
      "c6d51b1be83343a5b2cd2d198ab24347",
      "15656cf6d55c496c94209d8db9ca9932",
      "85e317d8d7fd4f13bb2747e8938dbd62",
      "fc5faccf5f3e4c26a8b6b6db24a61104",
      "d77bb607ef6c486cbe51497e7e2b04de",
      "2225479a2a064c628a7b7401c2b9b752",
      "9ec5da60f1724308a41e0fc007d2c923",
      "a9cb9fa401414181b1bee9c6008f291c",
      "0ff98940917a4610bcdbbb254f395c06",
      "3332467f235f4b5b91d9bdcb99a2b128",
      "bf83345af7d54c7baff2bbbc634fd584",
      "ae2def98cd3d4e07ae007ae147113c73",
      "ef768fa1333540648b644c8d9600521e",
      "2a6bba5f976d4f19bf4676ef6cd7aa3a",
      "1f8b521dc5e842039180246361939f45",
      "c27984f2c4d6491da7e169c4443ee53e",
      "989fc902f9a64a75aba87e0bc899f9b8",
      "db8b652c3fe54e8b9d0f556a87c42944",
      "d5c1fe4c2a4242d99541ab53ee2e0c98",
      "653135c3443e45359b3845edfdf5d750",
      "777905b6394f4713b2ae674e836dabef",
      "437b1ab97f2641539f866cbdb20877ce",
      "8bacf8533e894fe2879bf8a9789e455c",
      "9467f407c8a9496fac72afb6d06b0882",
      "e17fc8b4001b482b97cf082ff6537420",
      "28434107d24440efb88e8642a903967b",
      "000caeb3047e4d3e817a6f7be8421717",
      "3a9a5d8232bf47269867f5783998b700",
      "5e78fd9e70c442759f96279179ab9b96",
      "37b00b28b646489eaa193edd27d1193d",
      "83938744db21481f954579e0e50a0d50",
      "9f184ae7515546bd8c623b953086401f",
      "0ebcc8e7188f4b2ca3d29b1cb87a59c4",
      "51d9cbf4d25b4126a89be8b77bd034c5",
      "11625c63432a4c0aa98a21f512482da3",
      "07dde87d9edf4b71910843b9e235c51a",
      "935db5acf31c4a14b71b5e400f0c7cf9",
      "36776c7a9067408782ac469bcc688940"
     ]
    },
    "id": "YJUnGXzEqvtN",
    "outputId": "680a8404-fbb4-4a61-af29-ada82e8a6a8c"
   },
   "outputs": [],
   "source": [
    "qa_dataset.push_to_hub(\"kngrg/ru-QAmeleon\", private=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3DFUp4RCw8Tf"
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "import copy\n",
    "from collections import OrderedDict, defaultdict\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datasets import load_dataset, Dataset\n",
    "from typing import Dict, List, Tuple\n",
    "from llmtf.metrics import mean, metric_max_over_ground_truths, f1_macro_score\n",
    "import transformers.data.metrics.squad_metrics as squad_metrics\n",
    "import re\n",
    "from llmtf.base import Task, SimpleFewShotHFTask, LLM\n",
    "from difflib import SequenceMatcher\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "def metric_max_over_true(metric_fn, prediction, ground_truths):\n",
    "    scores_for_ground_truths = []\n",
    "    for ground_truth in ground_truths:\n",
    "        score = metric_fn(ground_truth, prediction)\n",
    "        scores_for_ground_truths.append(score)\n",
    "    return max(scores_for_ground_truths)\n",
    "\n",
    "\n",
    "\n",
    "class QATask(SimpleFewShotHFTask):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.method = 'generate'\n",
    "        self.dataset_name = 'QAmeleon'\n",
    "        self._max_new_tokens = 64\n",
    "\n",
    "    @classmethod\n",
    "    def name(cls):\n",
    "        return 'kngrg/ru-QAmeleon'\n",
    "\n",
    "    def dataset_args(self) -> Dict:\n",
    "        return {'path': 'kngrg/ru-QAmeleon'}\n",
    "\n",
    "    def aggregation(self) -> Dict:\n",
    "        return {\n",
    "          \"f1\": mean,\n",
    "          \"em\": mean\n",
    "        }\n",
    "\n",
    "    def evaluate(self, sample, y_pred) -> Dict:\n",
    "        y_true = sample['outputs']['segment']\n",
    "        f1 = metric_max_over_ground_truths(squad_metrics.compute_f1, y_pred, y_true)\n",
    "        em = metric_max_over_ground_truths(squad_metrics.compute_exact, y_pred, y_true)\n",
    "\n",
    "        return {\n",
    "          \"f1\": f1,\n",
    "          \"em\": em\n",
    "        }\n",
    "\n",
    "    def test_split_name(self) -> str:\n",
    "        return 'test'\n",
    "\n",
    "    def prompt_split_name(self) -> str:\n",
    "        return 'prompt'\n",
    "\n",
    "    def create_messages(self, sample, with_answer=None) -> List[Dict]:\n",
    "        messages = sample['messages']\n",
    "        inputs = sample['inputs']\n",
    "        for m in messages:\n",
    "            m['content'] = m['content'].format(**inputs)\n",
    "        return messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BZRJNdkb3R7v"
   },
   "outputs": [],
   "source": [
    "task = QATask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 882,
     "referenced_widgets": [
      "f1ad49308d9e41fb848142573db70527",
      "a21adea3795d406fb58699a67a7d2129",
      "6c954d97fe6d463fb983381024ceea5a",
      "657db32dda4f49e4b7ff55bc5f14282a",
      "170ad23b9b724af0a3aa9c6931e9ccd7",
      "635a566c7fa54fe49d514d24f83c5aa2",
      "c742d6e0002d4cc38eddf19c72f2f2a3",
      "9aff8e2645ef4ba2a73f118284105b76",
      "4ade04b41240420795a2e89673500538",
      "8b98ebe1356244c0a8016beb76b5b9da",
      "731445965615452e96105e475cc37845",
      "f75c582846824d15a89e0ec1bb3693b5",
      "08336cfdeebf4243b9e6b78271bca6d0",
      "57ec673543b749ae90645f70d139a1c2",
      "68f531cd3e3e44fdab74065454914fe7",
      "e73d103af5f849d0b51be25b974aa9bb",
      "8438478a4d144e428787f814bb63b509",
      "f831c1e2be2d4d3f8c13d167810a7d25",
      "4ec334ad8c954c4681fbf8e58110cb31",
      "34ac1e1acbe243f0b03a33ed1637b74c",
      "f47fd0f12856453987690fdced16ccde",
      "1fa99f4ee7024552ac741f9206748b49",
      "ca6898c1088549b6a34c0ee056d1f4f7",
      "d285e6178f2441878972e563b94f0542",
      "10524c1fc79e4799a059521a38ca2a3a",
      "0cb523ba94a34c8ebbf1093e0b970048",
      "038f0cfb817947a2b09ee1fe95bc3288",
      "379b72775e3a4c959ae0538775a18a86",
      "e01e19a212384f93aafa8497cdf2d44c",
      "45ead18d8bbe4cd19adc776eee67f0ab",
      "fbe49879d1084299a869323b5458422d",
      "cb5d092dc3b448df93e9df06449e6f27",
      "1dde9f8c211a4099af49e699a4cc63df",
      "699b9076029a4e23bf5618176a1dc121",
      "cc4a588e48474bb295fcd1a04c72f14b",
      "99f7c93ce706470db078d79c8f484414",
      "4fc502e1f9e24d6da057f28e869bfc25",
      "85c724f062654c4990c6a016fd130d86",
      "856a948a6efd4e91810eeba674549de2",
      "c4f0f1d6bb0e457ba64383ce875f78b1",
      "2cc05de00f224267ac411f00b0ac8e66",
      "c25f06a657134b17af729676553b15ed",
      "30277908065540e7b118eac5369f5a0a",
      "433c6c209a07459da0eaf0cf272f2ae5",
      "02d82baf00984774b3d35eb268b387c4",
      "daba889ec5f84c918e0fd3ef0c289dbb",
      "f84857dc917d47318246a415b445e559",
      "5deda3d84c1a4506ad85cac1e1e10c09",
      "118b4c7fde60418a82ebcec504455476",
      "204864bc4acb4abfa03d01415514b275",
      "01bd34334508443ba87f197271c360ed",
      "6e879e6dc9834c4b9e03b9ccb0aa9ab6",
      "7f1566abc54448ddb40b73657f90b359",
      "49dfa2694c6146ffa9dcb9d132636c02",
      "d439b26a07804d0d97bee8f4d35e5dae",
      "4c78840ff74b4faf869b5a22ea01f246",
      "382baff47ffe4f268dd002d82fe16c86",
      "685ec00378b24af696cc4ba9e607ccb8",
      "f5ee5a3807d84e859ae41181e49affc9",
      "afb5d49830e643f282d325763cf6abb6",
      "5b8474d9191846ac8c6849cded6911ab",
      "3e4f98e5b4564b84b27bc547b87fbdf6",
      "f23f29cab8e649e8b83f8b4103256ccc",
      "e810af237b6f42bf9583bc63a4628065",
      "1bf83099bf4942dab682cb16e4636e25",
      "4ca3f5d54ad04a64bf13784aa0543f0b",
      "ae1ba0d14c904e5c97d976b74d655ce9",
      "c600b46b499d491fba7595bfb6fac33f",
      "33153308fbfa42859f151af19191c6bd",
      "88aabd464043479fad7c77f37f84961d",
      "7d1cf3683d6349babc487be23c83f598",
      "7bff4a4ee3b64f69b84e7b60e5388622",
      "687db798e6b94f4d896f034add0dffbe",
      "17c953d2268b47e8b9a77fc8def57bec",
      "6c13827b88834c209337c6757935a8f3",
      "32256f03237a4e64b5e1d91e4796769c",
      "2ac5ffc385d440e2ac0460ab4d07376b",
      "9e8303b62d724c849107f0ed20d16ae9",
      "b8559eec49ba4d0a889117d4a147c646",
      "2e493643c8d940f288c346597745b88d",
      "08aa94c90de241a1b29cbd44a98a1f98",
      "ee7b4224c01548a4bbd194075d5eba9b",
      "25b68654b6be46cfb8e08ca2235365e7",
      "c9367aebe8d64bf4a82a2b3a8b31030d",
      "758dd2d2c7e649ffb5b2ec86233068e4",
      "775642b283974cf6a274d34046064fb6",
      "55be140cc0aa478194b1c5b75ccabe0f",
      "a69e9031048c4ebab1144d34a3f0f52b",
      "59b92643169044348a017d6d723746cc",
      "edc7dd597c6a4a40843d3836d9daf136",
      "cf8e245be3b741bf84c130675f154f28",
      "d9101c4f95034d02b8c2acb052772e4c",
      "623080523e9e477aa5fa43cef9480dca",
      "dea5052df7414ccb92402ff70247caac",
      "c4966afac8204c4293e28f77f6febcd8",
      "5dc2dc175cb449d4b581a97380ab818c",
      "660a200a957b47bb9d8fac7bc934ece4",
      "e7414c5ea3924903a723e41ee4168fff",
      "b92253add12b42979fea76453f0694f3",
      "07050bf80c01424bb97755d9de062e51",
      "781efb58799d44308ccf8c7cd603d046",
      "9de9c012e0394daab6268cfc6b439774",
      "989a17848b644610bb352a0b8a6a9c82",
      "0c989c0d6fd64f0db5ab6b28ea6bc539",
      "618f0620b2354df6919015f9c7435339",
      "c0c8dea8977b4a3db96a49dafc8dc44c",
      "751a308587b64d1fa41ca80125165ae0",
      "3ac2e0f01eb440bebd60b308bca35168",
      "48b1b4f2e75e4203b7eb9c41a0b0681d",
      "cecdd45a0d3243b98a6dd95b4b9c496a",
      "9030546bdc914116987028e88d41f6e3",
      "d6c9968e4e0244048991ef3a40aff4da",
      "01e82f5948a140019dedb9bc84f2f6f1",
      "d7316904f8884355b4ad5e0302675d62",
      "a7b48ca6c2744d0c999972b9314ee724",
      "3a55c9c2f5ee472ea8cd51741c282b62",
      "a297e79d849248f98e72f29cc3a1c134",
      "45fa57e1d93b4e9c9ca9b8e3fa6cf035",
      "2a7a1b8c76bd40449c35a654cce4c6f5",
      "32bd1468bc49469fbedc94a4d71ecd09",
      "6e4d1bffbd0d43e8bc3e42dfc561df0e"
     ]
    },
    "id": "DjW4E2Psl8vW",
    "outputId": "c601068f-be29-46b1-f371-5787262d231a"
   },
   "outputs": [],
   "source": [
    "#api_base = 'http://89.169.128.106:5000' # mistralai/Mistral-Nemo-Instruct-2407\n",
    "#api_base = 'http://89.169.128.106:5001' # Qwen/Qwen2.5-14B-Instruct\n",
    "#api_base = 'http://89.169.128.106:5002' # RefalMachine/ruadapt_qwen2.5_3B_ext_u48_instruct_v4\n",
    "\n",
    "from llmtf.model import HFModel\n",
    "\n",
    "model_name_or_path = 'Qwen/Qwen2.5-3B-Instruct'\n",
    "model = HFModel(conversation_template_path='conversation_configs/qwen2.json', device_map='cuda:0', attn_implementation=\"sdpa\")\n",
    "model.from_pretrained(model_name_or_path)\n",
    "\n",
    "model.generation_config.max_new_tokens = 200\n",
    "model.generation_config.repetition_penalty = 1.0\n",
    "model.generation_config.do_sample = False\n",
    "model.generation_config.temperature = 0.0\n",
    "model.generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bj9Lxsa2Olsz",
    "outputId": "1d31da08-95ae-4475-812f-7853525bf368"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: 2024-10-27 18:08:43,319: llmtf.base.hfmodel: Updated generation_config.eos_token_id: [151645]\n",
      "INFO:llmtf.base.hfmodel:Updated generation_config.eos_token_id: [151645]\n",
      "INFO: 2024-10-27 18:08:43,323: llmtf.base.hfmodel: Updated generation_config.stop_strings: ['<|im_end|>']\n",
      "INFO:llmtf.base.hfmodel:Updated generation_config.stop_strings: ['<|im_end|>']\n",
      "100%|██████████| 200/200 [00:00<00:00, 1320.98it/s]\n",
      "INFO: 2024-10-27 18:08:46,380: llmtf.base.kngrg/ru-QAmeleon: Loading Dataset: 3.05s\n",
      "INFO:llmtf.base.kngrg/ru-QAmeleon:Loading Dataset: 3.05s\n",
      "100%|██████████| 50/50 [20:02<00:00, 24.05s/it]\n",
      "INFO: 2024-10-27 18:28:48,677: llmtf.base.kngrg/ru-QAmeleon: Processing Dataset: 1202.29s\n",
      "INFO:llmtf.base.kngrg/ru-QAmeleon:Processing Dataset: 1202.29s\n",
      "INFO: 2024-10-27 18:28:48,680: llmtf.base.kngrg/ru-QAmeleon: Results for kngrg/ru-QAmeleon:\n",
      "INFO:llmtf.base.kngrg/ru-QAmeleon:Results for kngrg/ru-QAmeleon:\n",
      "INFO: 2024-10-27 18:28:48,686: llmtf.base.kngrg/ru-QAmeleon: {'f1': 0.028563285427308537, 'em': 0.0}\n",
      "INFO:llmtf.base.kngrg/ru-QAmeleon:{'f1': 0.028563285427308537, 'em': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from llmtf.evaluator import Evaluator\n",
    "evaluator = Evaluator()\n",
    "\n",
    "evaluator.evaluate_dataset(\n",
    "    task=task,\n",
    "    model=model,\n",
    "    output_dir='./qa_qwen',\n",
    "    max_len=4000,\n",
    "    few_shot_count=0,\n",
    "    generation_config=None, # will use model.generation_config by default\n",
    "    batch_size=4,\n",
    "    max_sample_per_dataset=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIBDXpc-fiQY",
    "outputId": "7c589c64-87be-451f-baef-b0236ab4ecc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kngrg_ru-QAmeleon.jsonl  kngrg_ru-QAmeleon_params.jsonl  kngrg_ru-QAmeleon_total.jsonl\n"
     ]
    }
   ],
   "source": [
    "!ls ./qa_qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EqUOg2ZRrpI5",
    "outputId": "f824d720-043d-4586-e4f5-efc4bb7cb8bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"task_name\": \"kngrg/ru-QAmeleon\",\n",
      "    \"results\": {\n",
      "        \"f1\": 0.028563285427308537,\n",
      "        \"em\": 0.0\n",
      "    },\n",
      "    \"leaderboard_result\": 0.014281642713654268\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!cat ./qa_qwen/kngrg_ru-QAmeleon_total.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rivX0DALXg3-",
    "outputId": "acba4183-bd6a-4431-cae8-2ca02d44eefa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"custom_generation_config\": null,\n",
      "    \"model_params\": {\n",
      "        \"model_name_or_path\": \"Qwen/Qwen2.5-3B-Instruct\",\n",
      "        \"generation_config\": {\n",
      "            \"eos_token_id\": [\n",
      "                151645\n",
      "            ],\n",
      "            \"max_length\": 32768,\n",
      "            \"max_new_tokens\": 200,\n",
      "            \"pad_token_id\": 151643,\n",
      "            \"stop_strings\": [\n",
      "                \"<|im_end|>\"\n",
      "            ],\n",
      "            \"temperature\": 0.0,\n",
      "            \"top_k\": 40,\n",
      "            \"top_p\": 0.9,\n",
      "            \"transformers_version\": \"4.45.2\",\n",
      "            \"trust_remote_code\": false\n",
      "        },\n",
      "        \"conversation_template\": {\n",
      "            \"system_prompt\": \"\",\n",
      "            \"system_message_template\": \"<|im_start|>{role}\\n{content}<|im_end|>\\n\",\n",
      "            \"user_message_template\": \"<|im_start|>{role}\\n{content}<|im_end|>\\n\",\n",
      "            \"bot_message_template\": \"<|im_start|>{role}\\n{content}<|im_end|>\\n\",\n",
      "            \"bot_message_template_incomplete\": \"<|im_start|>{role}\\n{content}\",\n",
      "            \"user_role\": \"user\",\n",
      "            \"bot_role\": \"assistant\",\n",
      "            \"system_role\": \"system\",\n",
      "            \"global_prefix\": \"\",\n",
      "            \"suffix\": \"<|im_start|>assistant\\n\",\n",
      "            \"add_special_tokens\": false,\n",
      "            \"eos_token\": \"<|im_end|>\"\n",
      "        },\n",
      "        \"load_in_8bit\": false,\n",
      "        \"torch_dtype\": \"auto\",\n",
      "        \"attn_implementation\": \"sdpa\",\n",
      "        \"device_map\": \"cuda:0\",\n",
      "        \"use_fast_tokenizer\": true,\n",
      "        \"leading_space\": false,\n",
      "        \"space_token\": null,\n",
      "        \"trust_remote_code\": false,\n",
      "        \"max_model_len\": 32768\n",
      "    },\n",
      "    \"task_params\": {\n",
      "        \"max_len\": 4000,\n",
      "        \"few_shot_count\": 0,\n",
      "        \"batch_size\": 4,\n",
      "        \"max_sample_per_dataset\": 200,\n",
      "        \"method\": \"generate\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!cat ./qa_qwen/kngrg_ru-QAmeleon_params.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 963,
     "referenced_widgets": [
      "fef5f18b918040e789f663526a5d3167",
      "7f84a5e160f648fe80a4083289205f17",
      "e9dd55051f8344719047698681ae0490",
      "4b58cddfd3304b6b9175496472006df7",
      "a3dd648c09e7441f909a350762aa287c",
      "9f3bb72f6a3b4defa0546fbbda0a218d",
      "c72532aa89194ed18ee53f5d4ab3613f",
      "bae78e566b8043d896204afd996cb62c",
      "51bbd1590ddf4c94a5e06bfa22121258",
      "80d2c1cd760b48aab6d306933e83a84e",
      "0e897df867de440a88ffc5179fc704af",
      "5a34ca9f598a4c6083cb3d0c1c1517c2",
      "ef2d3b5dce344c3f915296d1a5fda899",
      "650f6342dc95448cb32b84b129bc2ed3",
      "9fac2a0ab5f94691884561327e2f6a02",
      "cd30e4ba94284600accad1de3f819a18",
      "f7b0c04a46274151b46144fe8d5daaac",
      "461f705420b24d0890c0e2b239f8048e",
      "f99ee78e13024f009751aa229b13ecd7",
      "b0bc163c3711499ba8800346ca87401b",
      "846d960e1529480ba5646f1a6b571305",
      "84b002b61253466aabaa8f768e5404b7",
      "87fbf37de3474bf99047242fdc0334f1",
      "9c8f3a87916a418d8e00d85daf5987ef",
      "a08bfccc3f3149e2b24fe24b752f7c95",
      "9297ba8f486a42e482eb7e6c7f0c0c0c",
      "1f3a5025868b4ac9b763b90ab2373349",
      "d40ab1f9acfa4f5cb0882385ac8f3e7e",
      "b2cb3996bdaf4a41bdf0e1c6581654f9",
      "3dc18c706c614b40a126715bcd50cdb8",
      "63643d101ac54247a45199463b96c648",
      "aebb8a3464a848349694f00a12f59381",
      "ef744b0745e948fc858fbc54941d6a60",
      "670ff695bd7c4840b0b7449d69260bad",
      "fa25028a26484d949aa64f5fc1c60c50",
      "096691de83524827a1aa39cfaf9dab36",
      "90debbcf413640aea6d4a917d90760b6",
      "5e140f2ae03e469aa8ab16c324b4440d",
      "80a7b44a609542ad81c70606b480f971",
      "793d3e36846144768c2cf59cd2e9c9c3",
      "ffe02fd86bc14630879149d571ed97cf",
      "f29d00e0aef84c2d83cb04448d68c33e",
      "e1dd6e03334f4b03b1fd6563bdd77126",
      "bf4b75e5a2ce467d9af8ad4b35101b56",
      "1774847cc474442e8b449436092c7013",
      "b00c5d2c834542a0a8282aca1cd6ea7e",
      "f3573cada64d415a8a3dae32460b49e0",
      "e773c1850223437a925ac7e06b4ba09c",
      "c7c3d2d707384b75a98103d375ec6ee4",
      "fffa61c2199e45c5858cae4bb7a51764",
      "7472fbf5da544fcfa14ca4cfd0cc06f8",
      "2ae1a5bb4c134bf1a113afe025bd973d",
      "bb69daef4e4d42d588c0140727b42a5d",
      "a89d3c20e5e14f649790da765a5ed93a",
      "e8cab653fba34f5ea048c44503f01ea6",
      "0aeb0852eb594356ac8232bb38cf58fd",
      "03b9abfb36f34d64bfe9ac67be52ced3",
      "cf6b2ff623d247ba878e34bbdb64ead3",
      "7a77805da2ab4fa49f0e2603e323618f",
      "b29b8ddf363142739b504b66d450b089",
      "180ac39f2d624dce88079f83536e742b",
      "70b113611b124e68b949667a3e2c10c0",
      "2ba510651423406ab484a0dbddd226d7",
      "963e71a3556e4cafba32a4fb1dc239fb",
      "d976c919830447e7b6d4cf3b0e49a1bb",
      "0df81eb88b884562bdf61c074baf7f83",
      "229525161a044b20b4181dba47266564",
      "fed05015b6ec417a90dc5658600246d4",
      "14537cca987f4b49b8222fbb7a78978d",
      "da13269d291f4a2eb2add465e75cc960",
      "26f546dd6f0b4b35b8f74df415196a49",
      "f777203172ce4f0480a094ff0dac2bd7",
      "17a18b512424450eb49f24f3d036fad9",
      "e518df9afbbd42c7844de2997f47eb0d",
      "67d41eceb224404db7ba4dd2c4db2a34",
      "69f8e67ebfeb48bebf82987a40138834",
      "5ea558c746df44ceae504065bf63916d",
      "d96eebd7a5f3437595a29c5ea4622db2",
      "e148a8a4235b4bbab2f377d284686aea",
      "82d6586e8a0f4f68adf8e64592221e6a",
      "de2537d1dc8b4d63b2b4953e375d3ea0",
      "5ed11b6f7ecd45a784fc1a24a994f34a",
      "8343d6a246d042f8a7cbfdf838791419",
      "a18d9ec4bcbd465286405360d171b738",
      "8f6370063a33464aa339055a7af740a2",
      "e815de539e8d474c86875aeab5832b33",
      "a69de77620d041ae977f8ecacc52f557",
      "311a4a9572b546309e30d94c5862f574",
      "ea35d85976b04b6588c5d40dece59bc2",
      "16ad34c6b4b848d895365a5e641a0dbf",
      "d63b5bd32d9a49178aa014ebadb5f3e2",
      "2e75a48e65b14f1cabdc30d3801ecd29",
      "864267f3ab6e4bb298d61973087f4979",
      "2a15aaada8974ef4b6c1ae8c9b8ec925",
      "aa70f2475eb9401487071161af4db050",
      "4d5f279004a942a494703fcd3f72a6ca",
      "a51c9234c79041b493d290696d6a7950",
      "cd1762199ea94a958f973e84d6836a12",
      "26d6dbc714b94485a96dace128ecf82d",
      "ec12527a72224bc980852885f6c789dc",
      "7f2d0add87f34b23aa1f379131877b78",
      "53c33000ae0e48edb803674bbc8adcf6",
      "0615f3278005417a88bd26dd9727d219",
      "ded6f8eb9bef4deda11351925084861b",
      "2b7f3aceaf924655b47ae0e8b2818b59",
      "4be8c569bb524f03a3f3bf87334eb346",
      "8c3de96f2e2d42a3a7eabf770795da26",
      "f946c5354cf74fa3971a7a314475ffa0",
      "7655299563934b15a418507f8c10916b",
      "b675b8b4e41043798db408af1509b6ae",
      "b94eb17825cf4f6ca8ea2d7af8433525",
      "ab2284b76d50419ebb078035d4163d1f",
      "8ec1ed110d0144e9b5b5c7945ae64cc4",
      "115b09a329e241cabf4fd0b7c2e5ae1b",
      "de9039c3b7214c698cc28a86277342f9",
      "92049156eff74ffb9f0a7dde9a82a137",
      "fcb6fd54c321475aba67391620a87141",
      "d87136f9fb144c6a82d763d6deef9b18",
      "f4dfee4094404702876ee6d3dcbcb67e",
      "b1e9fac6c8114d0ea1131198a85a2128",
      "b43404a188474da0b32754948813df0f",
      "ef352d1fc3cd4a6c9824ecbbc0132ae3",
      "93d072129c6245d4b3b5f1e81dd2b014",
      "25be44a9c2a047ecb1d36f1e89cd8c3d",
      "5ae3ea1273c84371a2abb48b8fca56ef",
      "ead98af87ec54beca58a0617fc4b8da7",
      "88d6cdac8bbd44318cafbd7e5047f7cb",
      "758fb986f8b34f2ea3eff14f324ff60a",
      "15e1eaacad93437297389f493a2348bd",
      "a225fe7c578c41049030b95a8554786e",
      "f353788f9b684df39f2476f01829a417",
      "debf4f4885fc45dc9e87646022ec04d8",
      "73866949a53c4f638a50164bae66b573",
      "338b7e1cdf75431dac38351c9b84fff2",
      "0103ee41deab44e39d292a1f213a316e",
      "82cb3bf56f66414ea88d0d88878a3752",
      "e93c1c1658a84adfaa240d5a1af2b367",
      "db9834f9e4c2433f9a280652bfd0de9d",
      "c8e07c1cc2fc4972b759e26c38737675",
      "fc88e86786d94d44aebf339bed919b5a",
      "5b6ed4a2eb544138a5bb19f3666297ad",
      "f1d0ff536f5e427e985323f92c213219",
      "e17fe3028d8549eb9248a8542632def8"
     ]
    },
    "id": "WO-tdmbI5Vwg",
    "outputId": "1b6bf6e3-6392-43a5-bbd1-b1dd11a4824e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef5f18b918040e789f663526a5d3167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a34ca9f598a4c6083cb3d0c1c1517c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/35.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87fbf37de3474bf99047242fdc0334f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670ff695bd7c4840b0b7449d69260bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1774847cc474442e8b449436092c7013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aeb0852eb594356ac8232bb38cf58fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229525161a044b20b4181dba47266564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/195 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96eebd7a5f3437595a29c5ea4622db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea35d85976b04b6588c5d40dece59bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/3.37M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec12527a72224bc980852885f6c789dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/2.30M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94eb17825cf4f6ca8ea2d7af8433525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/12.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef352d1fc3cd4a6c9824ecbbc0132ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73866949a53c4f638a50164bae66b573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/759 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: 2024-10-27 18:51:12,263: llmtf.base.hfmodel: Set eos_token_id in generation_config to [147077]\n",
      "INFO:llmtf.base.hfmodel:Set eos_token_id in generation_config to [147077]\n",
      "WARNING: 2024-10-27 18:51:12,266: llmtf.base.hfmodel: Global prefix is equal to empty string!\n",
      "WARNING:llmtf.base.hfmodel:Global prefix is equal to empty string!\n",
      "INFO: 2024-10-27 18:51:12,270: llmtf.base.hfmodel: Model id: RefalMachine/ruadapt_qwen2.5_3B_ext_u48_instruct_v4\n",
      "INFO:llmtf.base.hfmodel:Model id: RefalMachine/ruadapt_qwen2.5_3B_ext_u48_instruct_v4\n",
      "INFO: 2024-10-27 18:51:12,273: llmtf.base.hfmodel: Leading space: False\n",
      "INFO:llmtf.base.hfmodel:Leading space: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"bos_token_id\": 147075,\n",
       "  \"eos_token_id\": [\n",
       "    147077\n",
       "  ],\n",
       "  \"max_length\": 32768,\n",
       "  \"max_new_tokens\": 200,\n",
       "  \"pad_token_id\": 147075,\n",
       "  \"stop_strings\": [\n",
       "    \"<|im_end|>\"\n",
       "  ],\n",
       "  \"temperature\": 0.0,\n",
       "  \"top_k\": 40,\n",
       "  \"top_p\": 0.9,\n",
       "  \"trust_remote_code\": false\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#api_base = 'http://89.169.128.106:5000' # mistralai/Mistral-Nemo-Instruct-2407\n",
    "#api_base = 'http://89.169.128.106:5001' # Qwen/Qwen2.5-14B-Instruct\n",
    "#api_base = 'http://89.169.128.106:5002' # RefalMachine/ruadapt_qwen2.5_3B_ext_u48_instruct_v4\n",
    "\n",
    "from llmtf.model import HFModel\n",
    "\n",
    "model_name_or_path = 'RefalMachine/ruadapt_qwen2.5_3B_ext_u48_instruct_v4'\n",
    "model = HFModel(conversation_template_path='conversation_configs/qwen2.json', device_map='cuda:0', attn_implementation=\"sdpa\")\n",
    "model.from_pretrained(model_name_or_path)\n",
    "\n",
    "model.generation_config.max_new_tokens = 200\n",
    "model.generation_config.repetition_penalty = 1.0\n",
    "model.generation_config.do_sample = False\n",
    "model.generation_config.temperature = 0.0\n",
    "model.generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgbYDuOoQU7H",
    "outputId": "21f0dcee-e17a-4a2a-9938-959b7f96518e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: 2024-10-27 18:51:12,305: llmtf.base.hfmodel: Updated generation_config.eos_token_id: [147077]\n",
      "INFO:llmtf.base.hfmodel:Updated generation_config.eos_token_id: [147077]\n",
      "INFO: 2024-10-27 18:51:12,312: llmtf.base.hfmodel: Updated generation_config.stop_strings: ['<|im_end|>']\n",
      "INFO:llmtf.base.hfmodel:Updated generation_config.stop_strings: ['<|im_end|>']\n",
      "100%|██████████| 200/200 [00:00<00:00, 920.16it/s] \n",
      "INFO: 2024-10-27 18:51:16,847: llmtf.base.kngrg/ru-QAmeleon: Loading Dataset: 4.53s\n",
      "INFO:llmtf.base.kngrg/ru-QAmeleon:Loading Dataset: 4.53s\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:623: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `40` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "100%|██████████| 50/50 [09:07<00:00, 10.96s/it]\n",
      "INFO: 2024-10-27 19:00:24,801: llmtf.base.kngrg/ru-QAmeleon: Processing Dataset: 547.95s\n",
      "INFO:llmtf.base.kngrg/ru-QAmeleon:Processing Dataset: 547.95s\n",
      "INFO: 2024-10-27 19:00:24,806: llmtf.base.kngrg/ru-QAmeleon: Results for kngrg/ru-QAmeleon:\n",
      "INFO:llmtf.base.kngrg/ru-QAmeleon:Results for kngrg/ru-QAmeleon:\n",
      "INFO: 2024-10-27 19:00:24,812: llmtf.base.kngrg/ru-QAmeleon: {'f1': 0.03285677635076812, 'em': 0.0}\n",
      "INFO:llmtf.base.kngrg/ru-QAmeleon:{'f1': 0.03285677635076812, 'em': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from llmtf.evaluator import Evaluator\n",
    "evaluator = Evaluator()\n",
    "\n",
    "evaluator.evaluate_dataset(\n",
    "    task=task,\n",
    "    model=model,\n",
    "    output_dir='./qa_qwen_adapt',\n",
    "    max_len=4000,\n",
    "    few_shot_count=0,\n",
    "    generation_config=None, # will use model.generation_config by default\n",
    "    batch_size=4,\n",
    "    max_sample_per_dataset=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0dxbs3lERAc6",
    "outputId": "788d8bfe-5fd3-461a-c045-1bdc34dd935b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kngrg_ru-QAmeleon.jsonl  kngrg_ru-QAmeleon_params.jsonl  kngrg_ru-QAmeleon_total.jsonl\n"
     ]
    }
   ],
   "source": [
    "!ls ./qa_qwen_adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJuUYrWPTuRH",
    "outputId": "58b15b01-48cf-497a-d502-3a132b677243"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"task_name\": \"kngrg/ru-QAmeleon\",\n",
      "    \"results\": {\n",
      "        \"f1\": 0.03285677635076812,\n",
      "        \"em\": 0.0\n",
      "    },\n",
      "    \"leaderboard_result\": 0.01642838817538406\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!cat ./qa_qwen_adapt/kngrg_ru-QAmeleon_total.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bQ4mnIWPWc1f",
    "outputId": "71a77a16-37db-48dd-845e-b1f7c487b724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"custom_generation_config\": null,\n",
      "    \"model_params\": {\n",
      "        \"model_name_or_path\": \"RefalMachine/ruadapt_qwen2.5_3B_ext_u48_instruct_v4\",\n",
      "        \"generation_config\": {\n",
      "            \"bos_token_id\": 147075,\n",
      "            \"eos_token_id\": [\n",
      "                147077\n",
      "            ],\n",
      "            \"max_length\": 32768,\n",
      "            \"max_new_tokens\": 200,\n",
      "            \"pad_token_id\": 147075,\n",
      "            \"stop_strings\": [\n",
      "                \"<|im_end|>\"\n",
      "            ],\n",
      "            \"temperature\": 0.0,\n",
      "            \"top_k\": 40,\n",
      "            \"top_p\": 0.9,\n",
      "            \"transformers_version\": \"4.45.2\",\n",
      "            \"trust_remote_code\": false\n",
      "        },\n",
      "        \"conversation_template\": {\n",
      "            \"system_prompt\": \"\",\n",
      "            \"system_message_template\": \"<|im_start|>{role}\\n{content}<|im_end|>\\n\",\n",
      "            \"user_message_template\": \"<|im_start|>{role}\\n{content}<|im_end|>\\n\",\n",
      "            \"bot_message_template\": \"<|im_start|>{role}\\n{content}<|im_end|>\\n\",\n",
      "            \"bot_message_template_incomplete\": \"<|im_start|>{role}\\n{content}\",\n",
      "            \"user_role\": \"user\",\n",
      "            \"bot_role\": \"assistant\",\n",
      "            \"system_role\": \"system\",\n",
      "            \"global_prefix\": \"\",\n",
      "            \"suffix\": \"<|im_start|>assistant\\n\",\n",
      "            \"add_special_tokens\": false,\n",
      "            \"eos_token\": \"<|im_end|>\"\n",
      "        },\n",
      "        \"load_in_8bit\": false,\n",
      "        \"torch_dtype\": \"auto\",\n",
      "        \"attn_implementation\": \"sdpa\",\n",
      "        \"device_map\": \"cuda:0\",\n",
      "        \"use_fast_tokenizer\": true,\n",
      "        \"leading_space\": false,\n",
      "        \"space_token\": null,\n",
      "        \"trust_remote_code\": false,\n",
      "        \"max_model_len\": 32768\n",
      "    },\n",
      "    \"task_params\": {\n",
      "        \"max_len\": 4000,\n",
      "        \"few_shot_count\": 0,\n",
      "        \"batch_size\": 4,\n",
      "        \"max_sample_per_dataset\": 200,\n",
      "        \"method\": \"generate\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!cat ./qa_qwen_adapt/kngrg_ru-QAmeleon_params.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftZ-qjwsWjDZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
